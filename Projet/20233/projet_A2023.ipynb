{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbf782b",
   "metadata": {},
   "source": [
    "# MTH3302 : Méthodes probabilistes et statistiques pour l'I.A.\n",
    "\n",
    "Jonathan Jalbert<br/>\n",
    "Professeur agrégé au Département de mathématiques et de génie industriel<br/>\n",
    "Polytechnique Montréal<br/>\n",
    "\n",
    "\n",
    "---\n",
    "# Projet A2023 : Prédiction du nombre de passages sur le REV \n",
    "\n",
    "\n",
    "L’analyse des données ouvertes de la circulation sur la rue Saint-Denis révèle une hausse importante de l’utilisation du vélo par rapport aux autres véhicules, au tournant de l’installation du Réseau express vélo (REV) en 2020 comme le rapporte le journal *Le Devoir* dans cet [article](https://www.ledevoir.com/environnement/735849/le-ratio-velo-auto-s-ameliore-sur-le-rev-saint-denis). Serez-vous en mesure de prédire l'achalandage du REV pour l'année 2023, de janvier à septembre ? Est-ce que les conditions météorologiques ont une influence sur le nombre de passages ? Ce sont des questions que vous aurez l'occasion d'étudier dans le cadre de ce projet.\n",
    "\n",
    "**But** : Prédire le nombre de passages journalier sur le REV en direction nord à l'intersection de la rue St-Denis et de la Piste des Carrières pour tous les jours entre le 1er janvier 2023 et le 30 septembre 2023.\n",
    "\n",
    "**Objectifs spécifiques non exhaustifs**\n",
    "1. Effectuer une analyse exploratoire des données afin d'extraire qualitativement certains les potentiels liens entre les variables.\n",
    "2. Élaborer plusieurs modèles prédictifs pour le nombre de passages journaliers sur le REV en fonction des différentes variables explicatives à disposition (nombre de passages sur d'autres tronçons, conditions météorologiques, etc.).\n",
    "3. Sélectionner le meilleur modèle prédicitif à l'aide d'un critère choisi.\n",
    "4. Exploiter le modèle choisi pour effectuer vos prédictions.\n",
    "\n",
    "Ces étapes peuvent être recommencées autant de fois que nécessaire afin d'obtenir le meilleur modèle prédictif possible.\n",
    "\n",
    "La description du projet est disponible à l'adresse suivante : https://www.kaggle.com/t/b2f3163a94434f0da9e532139744c49d\n",
    "\n",
    "Ce calepin Jupyter de base permet de charger les données fournies. La dernière section détaille la génération du fichier des prédictions afin de le soumettre sur Kaggle dans le bon format.\n",
    "\n",
    "### Données\n",
    "\n",
    "Dans un premier temps, vous devrez récupérer les données sur Kaggle. Les fichiers disponibles sont les suivants :\n",
    "- train.csv\n",
    "- test.csv\n",
    "\n",
    "**Déposez ces fichiers dans le répertoire de ce calepin.**\n",
    "\n",
    "Le fichier *train.csv* contient les conditions météorologiques ainsi que le nombre de passages enregistrés sur le tronçon du REV à l'intersection St-Denis/Castelnau (45.53905N,-73.61687W). Voici la description des variables :\n",
    "\n",
    "- Date : date\n",
    "- MaxTemp : Température maximale (°C)\n",
    "- MinTemp : Température minimale (°C)\n",
    "- MeanTemp : Température moyenne (°C)\n",
    "- TotalRain : Accumulation totale de pluie (mm)\n",
    "- TotalSnow : Accumulation totale de neige (cm)\n",
    "- TotalPrecip : Accumulation totale de précipitations (pluie + neige, mm)\n",
    "- SnowGrnd : Couvert de neige au sol (cm)\n",
    "- SpdGust : Vitesse maximale des rafales de vent (km/h)\n",
    "- REV : Nombre de passages de vélo au compteur sur le REV en direction sud à l'intersection St-Denis/Castelnau \n",
    "\n",
    "Le fichier *test.csv* contient les conditions météorologiques pour l'année 2023 mais pas le nombre de passages sur le REV, la variable que vous devrez prédire. Le fichier contient aussi l'identifiant (:ID) pour les prédictions. La qualité de vos prédictions sera ensuite évaluée avec le [*Root Mean Squared Log Error*](https://www.kaggle.com/code/carlolepelaars/understanding-the-metric-rmsle) lorsque vous les téléverserez sur Kaggle. Vos prédictions seront comparées à celles des autres équipes de la classe.\n",
    "\n",
    "\n",
    "### Consignes\n",
    "\n",
    "- Vous devez constituer une équipe de 3 à 5 personnes.\n",
    "- Au moins une solution doit être proposée sur Kaggle.\n",
    "- Utilisez votre identifiant d'équipe pour téléverser vos prédictions sur Kaggle.\n",
    "- Un seul calepin *.ipynb* par équipe doit être remis. Ce fichier devra documenter et illustrer la procédure qui vous a permis de produire vos meilleures prédictions. Ce fichier constitue le rapport final du projet.\n",
    "- Le langage Julia doit être utilisé.\n",
    "- Votre démarche doit être rigoureusement justifiée (consultez la grille de correction pour vous orienter).\n",
    "\n",
    "### Quelques conseils\n",
    "\n",
    "Votre calepin doit permettre à une personne à l'extérieur de l'équipe de comprendre votre démarche et de reproduire vos résultats. Par exemple, une bonne façon de faire consiste à expliquer dans une cellule de texte la tâche qui est accomplie dans la cellule de code suivante. \n",
    "\n",
    "Je vous encourage fortement à faire une analyse exploratoire des données pour développer une meilleure expertise sur le problème. C'est une étape qui est toujours négligée mais qui est essentielle. C'est avec l'analyse exploratoire que vous viendra des idées d'amélioration, comme par exemple créer de nouvelles variables explicatives.\n",
    "\n",
    "Vous pouvez utiliser directement tout ce qui se trouve dans les notes de cours sans explication et toutes les librairies utilisées dans le cours (incluant mes fonctions).\n",
    "\n",
    "Ce calepin contient un modèle très simple de prédiction : on n'utilise qu'une seule variable explicative. Ce sera votre travail d'améliorer ces prédictions avec la méthode et les variables de votre choix.\n",
    "\n",
    "S'il y a des données manquantes, ce sera à vous de traiter ce problème. Vous devriez développer une méthode d'imputation (de remplacement) des données manquantes.\n",
    "\n",
    "Attention aux données aberrantes. Elles peuvent faire dérailler tous le modèle prédictif si elle ne sont pas prises en compte.\n",
    "\n",
    "Prenez la peine de documenter succinctement les essais infructueux. Ce n'est pas nécessaire de les expliquer en détails, mais c'est important de les mentionner dans la discussion avec une raison possible de leur échec. De cette façon, une personne qui reprendra votre travail dans le futur ne perdra pas de temps à réessayer une méthode infructueuse déjà testée.\n",
    "\n",
    "Vous pouvez aussi indiquer dans votre rapport les raisons qui vous font croire pourquoi une méthode a moins bien performée de ce qui était attendu. Vous pouvez également mentionner ce que vous auriez pu tenter si vous aviez eu plus de temps ou plus de données. L'idée est de guider l'analyste qui prendrait la relève de votre travail.\n",
    "\n",
    "Vous êtes limités à deux soumissionspar jour et par équipe sur Kaggle. Je vous suggère donc de bien tester vos modèles localement et de ne téléverser que vos meilleurs prédictions de la journée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583917f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Dates, Gadfly, GLM, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460eab0",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Chargement de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CSV.read(\"train.csv\", DataFrame)\n",
    "first(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a8350",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Analyse exploratoire\n",
    "\n",
    "Cette section consitue une analyse exploratoire superficielle permettant de se familiariser avec les données. C'est une analyse exploratoire sommaire. Je vous encourage fortement à poursuivre cette analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e685b4",
   "metadata": {},
   "source": [
    "#### 2.1 Nombre de passages sur le REV en fonction de la date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db83919",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(12cm, 10cm)\n",
    "plot(train, x=:Date, y=:REV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775f54c",
   "metadata": {},
   "source": [
    "#### 2.2 Nombre de passages sur le REV en fonction des conditions météorologiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7174182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "\n",
    "fig1 = plot(train, x=:MeanTemp, y=:REV)\n",
    "fig2 = plot(train, x=:TotalPrecip, y=:REV)\n",
    "fig3 = plot(train, x=:SnowGrnd, y=:REV)\n",
    "fig4 = plot(train, x=:SpdGust, y=:REV)\n",
    "\n",
    "gridstack([fig1 fig2; fig3 fig4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282da10",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Ajustement d'un modèle de régression linéaire\n",
    "\n",
    "Pour cet exemple simple, on n'utilise que la température moyenne pour prédire le logarithme des passages sur le REV avec la régression linéaire. On pourrait aussi pu utiliser un modèle linéaire généralisé pour modéliser le nombre de passages avec la loi de Poisson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e2428",
   "metadata": {},
   "source": [
    "#### 3.1. Transformation du nombres de passages à l'échelle logarithmique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(train)\n",
    "data[!,:REV] = log.(train.REV)\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b969a",
   "metadata": {},
   "source": [
    "#### 3.2. Ajustement du modèle de régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ef4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(REV ~ MeanTemp), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af68dc",
   "metadata": {},
   "source": [
    "#### 3.3. Validation graphique\n",
    "\n",
    "Pour avoir un aperçu de la qualité de la regression, on ajoute la droite de régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "β̂ = coef(model)\n",
    "\n",
    "points = layer(data, x=:MeanTemp, y=:REV, Geom.point)\n",
    "line = layer(x->β̂[1]+β̂[2]*x, -25, 35, Theme(default_color=\"red\"))\n",
    "\n",
    "plot(line, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46cd339",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Estimation du nombre de passages de l'ensemble de test\n",
    "\n",
    "On utilise le modèle simple de la section précédente pour le nombre de passages pour chacun des jours de l'ensemble de test.\n",
    "\n",
    "#### 4.1 Chargement des données de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5638067",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CSV.read(\"test.csv\", DataFrame)\n",
    "first(test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6624e4a",
   "metadata": {},
   "source": [
    "#### 4.2 Traitement des valeurs manquantes\n",
    "\n",
    "Dans l'ensemble de test, il y a des jours pour lesquelles la température moyenne (la variable explicative utilisée dans le modèle simple) est manquante. \n",
    "\n",
    "Ici, je propose de remplacer les valeurs manquantes par la température moyenne du jour précédent. C'est une façon simple et même peut-être simpliste de traiter les valeurs manquantes. Ce sera à vous de décider comment les traiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aafa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de jours où il manque la température moyenne\n",
    "count(ismissing.(test.MeanTemp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccb492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    coalesceWithPrevious!(x::AbstractArray{T} where T <: Union{Missing, Real})\n",
    "    \n",
    "Coalesce missing values with the previous non-missing.\n",
    "\n",
    "### Details\n",
    "\n",
    "If the first element of `x` is missing, than it is replace with the first non-missing value.\n",
    "\"\"\"\n",
    "function coalesceWithPrevious!(x::AbstractArray{T} where T <: Union{Missing, Real})\n",
    "    \n",
    "    if ismissing(x[1])\n",
    "        x[1] = x[findfirst(.!(ismissing.(x)))]\n",
    "    end\n",
    "        \n",
    "    ind = findall(ismissing.(x))\n",
    "    \n",
    "    for i in ind\n",
    "        x[i] = x[i-1]\n",
    "    end\n",
    "    \n",
    "    return x\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement des valeurs manquantes par la valeur précédente.\n",
    "coalesceWithPrevious!(test.MeanTemp)\n",
    "\n",
    "# Nombre de valeurs manquantes après le remplacement\n",
    "count(ismissing.(test.MeanTemp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4950d6ec",
   "metadata": {},
   "source": [
    "#### 4.3 Prédictions\n",
    "\n",
    "On retransforme les prédictions dans l'espace logarithmique pour obtenir des nombres de passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = exp.(predict(model, test))\n",
    "\n",
    "# Vous pouvez transformer vos prédictions en valeurs entières si vous le souhaitez. Mais ce n'est pas nécessaire.\n",
    "# predictions = Int.(round.(predictions, digits=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faed591",
   "metadata": {},
   "source": [
    "#### 4.4 Préparation du fichier des préditions pour téléverser sur Kaggle\n",
    "\n",
    "Le fichier *benchmark_predictions.csv* généré peut être téléversé sur Kaggle. Il est composé d'une colonne d'identifiants (:ID) et d'une colonne de la prédiction (:REV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b66b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_predictions = DataFrame(ID = test.ID, REV=predictions)\n",
    "first(benchmark_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ae7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(\"benchmark_predictions.csv\", benchmark_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9450f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
